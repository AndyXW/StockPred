{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models import AlphaNetV3\n",
    "from dataset import StockDataset\n",
    "from utils import AverageMeter\n",
    "from data import TrainValData, TimeSeriesData\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_y(df_y):\n",
    "    df_y_mean = df_y.mean(axis=1)\n",
    "    df_y_std = df_y.std(axis=1)\n",
    "    max_5_sigma = df_y_mean + 5 * df_y_std\n",
    "    min_5_sigma = df_y_mean - 5 * df_y_std\n",
    "    \n",
    "    for row in range(df_y.shape[0]):\n",
    "        df_y.iloc[row][df_y.iloc[row]>max_5_sigma.values[row]] = np.nan\n",
    "        df_y.iloc[row][df_y.iloc[row]<min_5_sigma.values[row]] = np.nan\n",
    "\n",
    "    df_y_q_33 = df_y.quantile(q=0.33, axis=1)\n",
    "    df_y_q_66 = df_y.quantile(q=0.67, axis=1)\n",
    "\n",
    "    for row in range(df_y.shape[0]):\n",
    "    # row = 700\n",
    "        rank_0 = (df_y.iloc[row] <= df_y_q_33.values[row])\n",
    "        rank_1 = ((df_y.iloc[row]>df_y_q_33.values[row]) & (df_y.iloc[row]<=df_y_q_66.values[row]))\n",
    "        rank_2 = (df_y.iloc[row]>df_y_q_66.values[row])\n",
    "\n",
    "        df_y.iloc[row][rank_0] = 0\n",
    "        df_y.iloc[row][rank_1] = 1\n",
    "        df_y.iloc[row][rank_2] = 2\n",
    "\n",
    "\n",
    "def to_one_hot(y, num_cls=3):\n",
    "    one_hot_label = np.empty((len(y), num_cls))\n",
    "    one_hot_label[:] = np.NaN\n",
    "    y = y.astype(np.int64)\n",
    "    for row in range(len(one_hot_label)):\n",
    "        if y[row] >= 0 and y[row] < num_cls:\n",
    "            label = np.zeros(num_cls)\n",
    "            label[y[row]] = 1\n",
    "            one_hot_label[row] = label\n",
    "    return one_hot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/work/bd/summer2022/insample/datacache'\n",
    "dailydata = os.path.join(data_path, 'dailydata')\n",
    "labeldata = os.path.join(data_path, 'labeldata')\n",
    "\n",
    "df_close = pd.read_parquet(os.path.join(dailydata, 'close.parquet'))\n",
    "df_high = pd.read_parquet(os.path.join(dailydata, 'high.parquet'))\n",
    "df_low = pd.read_parquet(os.path.join(dailydata, 'low.parquet'))\n",
    "df_open = pd.read_parquet(os.path.join(dailydata, 'open.parquet'))\n",
    "df_tvrvalue = pd.read_parquet(os.path.join(dailydata, 'tvrvalue.parquet'))\n",
    "df_tvrvolume = pd.read_parquet(os.path.join(dailydata, 'tvrvolume.parquet'))\n",
    "\n",
    "df_y = pd.read_parquet(os.path.join(labeldata, 'Y_0.parquet'))\n",
    "preprocess_y(df_y=df_y)\n",
    "\n",
    "features = [df_open, df_high, df_low, df_tvrvalue, df_tvrvolume, df_close]\n",
    "stock_data_list = []\n",
    "\n",
    "stocks = df_open.columns.values\n",
    "for stock in stocks:\n",
    "    one_stock_features = []\n",
    "    for feature in features:\n",
    "        one_stock_features.append(feature[stock].values[:-2].reshape(-1, 1))\n",
    "    stock_np_features = np.concatenate(one_stock_features, axis=1)\n",
    "    dates = feature.index.values[:-2]\n",
    "    # labels = np.zeros(len(df_y[stock].values[1:]), 3)\n",
    "    # labels[:, ]\n",
    "    # labels = df_y[stock].values[1:]\n",
    "    labels = to_one_hot(df_y[stock].values[1:])\n",
    "    # print(stock_np_features.shape, dates.shape, labels.shape)\n",
    "    stock_data_list.append(TimeSeriesData(dates=dates, data=stock_np_features, labels=labels))\n",
    "\n",
    "train_val_data = TrainValData(time_series_list=stock_data_list, train_length=800, validate_length=150, history_length=10, train_val_gap=10, sample_step=1)\n",
    "train, val, dates_info = train_val_data.get(20180102, order='by_date')\n",
    "\n",
    "val_dataset = StockDataset(stock_data=val[0], stock_label=val[1])\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=4096, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = StockDataset(stock_data=train[0], stock_label=train[1])\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=4096, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model = AlphaNetV3(feat_dim=6, hidden_dim=30, num_layers=2, dropout=0.0, num_classes=3)\n",
    "ckpt = torch.load('results/baseline_pce_tm_4.5_lr0.001/best_model.ckpt', map_location='cpu')\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': 1.0853035265463058}\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "losses = AverageMeter()\n",
    "acces = AverageMeter()\n",
    "p_outputs = []\n",
    "p_ys = []\n",
    "preds = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for i, (feat, label) in enumerate(val_loader):\n",
    "        feat = feat.to(device).to(torch.float32)\n",
    "        label = label.to(device).to(torch.float32)\n",
    "\n",
    "        output = model(feat)\n",
    "        loss = criterion(output, label)\n",
    "        prediction = output.argmax(dim=1)\n",
    "        labelindex = label.argmax(dim=1)\n",
    "        acc = accuracy_score(labelindex.cpu().numpy(), prediction.cpu().numpy())\n",
    "        acces.update(acc, feat.size(0))\n",
    "\n",
    "        p_outputs.append(output.cpu().numpy())\n",
    "        p_ys.append(label.cpu().numpy())\n",
    "        \n",
    "        preds.append(prediction.cpu().numpy())\n",
    "        labels.append(labelindex.cpu().numpy())\n",
    "\n",
    "        losses.update(loss.item(), feat.size(0))\n",
    "ret = {'val_loss': losses.avg}\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation\n",
    "# p_output = np.concatenate(p_outputs, axis=0)\n",
    "# p_y = np.concatenate(p_ys, axis=0)\n",
    "# print(len(p_y))\n",
    "# corr = 0\n",
    "# for i in range(len(p_y)):\n",
    "#     corr += np.corrcoef(p_output[i, :], p_y[i, :])[0, 1]\n",
    "# correlation = corr/len(p_y)\n",
    "# print(f\"correlation: {correlation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_preds = np.concatenate(preds, axis=0)\n",
    "total_labels = np.concatenate(labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2924,  0.1035,  0.2921],\n",
       "        [ 0.2060, -0.2860,  0.2026],\n",
       "        [-0.0027,  0.0092, -0.0009],\n",
       "        ...,\n",
       "        [ 0.2408, -0.6489,  0.2204],\n",
       "        [ 0.3515, -0.1712,  0.3376],\n",
       "        [ 0.1205, -0.1768,  0.1192]], device='cuda:0')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = labelindex == 1\n",
    "output[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.3804113594467117, recall: 0.39301411655230734, precision: 0.41423833991569414, accuracy: 0.392152034503856\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(total_labels, total_preds, average='macro')\n",
    "recall = recall_score(total_labels, total_preds, average='macro')\n",
    "precision = precision_score(total_labels, total_preds, average='macro')\n",
    "print(f\"f1_score: {f1}, recall: {recall}, precision: {precision}, accuracy: {acces.avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[348521, 114367, 199067]\n",
      "[219132, 224969, 217854]\n",
      "[0.5490312785612315, 0.6730019412195694, 0.5622708492269112]\n",
      "[0.4741135869976905, 0.3621130678737299, 0.30500742346871473]\n",
      "[0.6140864866838253, 0.273099849312572, 0.29185601366052494]\n",
      "[0.38610585875743497, 0.5372091599849607, 0.31940000100468685]\n"
     ]
    }
   ],
   "source": [
    "pred_classes_num = []\n",
    "label_classes_num = []\n",
    "acc_classes = []\n",
    "f1_classes = []\n",
    "recall_classes = []\n",
    "precision_classes = []\n",
    "\n",
    "for i in range(3):\n",
    "    preds_i = (total_preds==i)\n",
    "    labels_i = (total_labels==i)\n",
    "    pred_classes_num.append((preds_i).sum())\n",
    "    label_classes_num.append((labels_i).sum())\n",
    "    acc_classes.append(accuracy_score(labels_i, preds_i))\n",
    "    f1_classes.append(f1_score(labels_i, preds_i))\n",
    "    recall_classes.append(recall_score(labels_i, preds_i))\n",
    "    precision_classes.append(precision_score(labels_i, preds_i))\n",
    "\n",
    "    \n",
    "print(pred_classes_num)\n",
    "print(label_classes_num)\n",
    "print(acc_classes)\n",
    "print(f1_classes)\n",
    "print(recall_classes)\n",
    "print(precision_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[134566,  23965,  60601],\n",
       "       [ 88646,  61439,  74884],\n",
       "       [125309,  28963,  63582]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(total_labels, total_preds)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [71], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m label \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m----> 2\u001b[0m tensor([[\u001b[39m0.3568\u001b[39m, \u001b[39m0.3054\u001b[39m, \u001b[39m0.3379\u001b[39m],\n\u001b[1;32m      3\u001b[0m         [\u001b[39m0.3461\u001b[39m, \u001b[39m0.2822\u001b[39m, \u001b[39m0.3717\u001b[39m],\n\u001b[1;32m      4\u001b[0m         [\u001b[39m0.2830\u001b[39m, \u001b[39m0.4342\u001b[39m, \u001b[39m0.2828\u001b[39m],\n\u001b[1;32m      5\u001b[0m         [\u001b[39m0.3920\u001b[39m, \u001b[39m0.2397\u001b[39m, \u001b[39m0.3684\u001b[39m],\n\u001b[1;32m      6\u001b[0m         [\u001b[39m0.3633\u001b[39m, \u001b[39m0.2465\u001b[39m, \u001b[39m0.3902\u001b[39m],\n\u001b[1;32m      7\u001b[0m         [\u001b[39m0.4089\u001b[39m, \u001b[39m0.2402\u001b[39m, \u001b[39m0.3509\u001b[39m]], device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tensor' is not defined"
     ]
    }
   ],
   "source": [
    "label = 1\n",
    "tensor([[0.3568, 0.3054, 0.3379],\n",
    "        [0.3461, 0.2822, 0.3717],\n",
    "        [0.2830, 0.4342, 0.2828],\n",
    "        [0.3920, 0.2397, 0.3684],\n",
    "        [0.3633, 0.2465, 0.3902],\n",
    "        [0.4089, 0.2402, 0.3509]], device='cuda:0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "687a147c0ca2918c1c7a145e283081ccb27aa2c5a414bec45890f7b172940bf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
